from langchain_openai import ChatOpenAI
from core.config import LLM_API_KEY, LLM_BASE_URL, LLM_MODEL_NAME
import re
import ast

# åˆå§‹åŒ–å®¢æˆ·ç«¯ (ä½¿ç”¨ LangChain ç»Ÿä¸€æ¥å£)
llm = None

# 1. ä¼˜å…ˆæ£€æŸ¥ SiliconFlow / DeepSeek (OpenAI å…¼å®¹æ¥å£)
if LLM_API_KEY:
    print(f"âœ… ä½¿ç”¨ SiliconFlow/DeepSeek API (model: {LLM_MODEL_NAME})")
    llm = ChatOpenAI(
        model=LLM_MODEL_NAME,
        api_key=LLM_API_KEY,
        base_url=LLM_BASE_URL,
        temperature=0.7
    )
else:
    print("âš ï¸ æœªé…ç½® SiliconFlow API Keyï¼Œç”ŸæˆåŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")

class MockResponse:
    def __init__(self, content):
        self.content = content

def safe_invoke(messages):
    """
    ç»Ÿä¸€çš„ LLM è°ƒç”¨å°è£…
    """
    if not llm:
        return MockResponse("ğŸ¤– (æœªé…ç½® API Keyï¼Œè¯·æŸ¥çœ‹ä¸‹æ–¹èœè°±)")

    try:
        # ç›´æ¥è°ƒç”¨é…ç½®å¥½çš„ LLM
        return llm.invoke(messages)
    except Exception as e:
        print(f"âŒ [SafeInvoke] LLM è°ƒç”¨å¤±è´¥: {e}")
        return MockResponse("ğŸ¤– (AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ API Key æˆ–ç½‘ç»œ)")

def smart_select_and_comment(query: str, candidates: list):
    """
    æ™ºèƒ½ä¼˜é€‰ Rerank (çµæ´»ç‰ˆ)
    ä¸å†æ­»æ¿è¿‡æ»¤ï¼Œè€Œæ˜¯ä¾§é‡äºâ€œæ¨è + å»ºè®®â€
    """
    if not llm:
        return 0, "API Key æœªé…ç½®ï¼Œé»˜è®¤æ¨èï¼š"
    
    if not candidates:
        return 0, "æ²¡æœ‰å€™é€‰èœè°±ã€‚"

    # 1. æ„å»ºå€™é€‰åˆ—è¡¨
    candidates_str = ""
    for i, doc in enumerate(candidates):
        snippet = doc.get('content', '')[:150].replace('\n', ' ')
        candidates_str += (
            f"é€‰é¡¹[{i}]: {doc.get('name')}\n"
            f"   - æ ‡ç­¾: {doc.get('tags', [])}\n"
            f"   - ç®€ä»‹: {snippet}...\n\n"
        )

    # =====================================================
    # âœ… ä¼˜åŒ–åçš„ Promptï¼šæ›´åƒä¸€ä¸ªæ‡‚å¾—å˜é€šçš„å¤§å¨
    # =====================================================
    system_prompt = """
    ä½ æ˜¯ä¸€ä½èªæ˜ã€å¹½é»˜ä¸”æ‡‚å˜é€šçš„ç§å®¶å¤§å¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ç»™å®šçš„å€™é€‰èœè°±ä¸­ï¼Œä¸ºç”¨æˆ·æ¨è**æœ€åˆé€‚**çš„ä¸€é“ã€‚

    ã€æ¨èé€»è¾‘ã€‘ï¼š
    1. **æ‰¾æœ€å¤§å…¬çº¦æ•°**ï¼šä¼˜å…ˆé€‰æ‹©é£Ÿæã€å£å‘³æœ€æ¥è¿‘ç”¨æˆ·éœ€æ±‚çš„èœã€‚
    2. **å€Ÿå£³ä¸Šå¸‚ (Bridging) - æ ¸å¿ƒèƒ½åŠ›**ï¼š
       - å¦‚æœæ¨èçš„èœè°±ç¼ºå°‘ç”¨æˆ·æ‰‹é‡Œçš„æŸä¸ªé£Ÿæï¼Œ**å¿…é¡»**åœ¨ç†ç”±é‡Œå»ºè®®ç”¨æˆ·â€œåœ¨ç¬¬å‡ æ­¥åŠ è¿›å»â€ã€‚
       - ä¾‹å¦‚ï¼šç”¨æˆ·æœ‰â€œç‰ç±³â€ï¼Œä½†ä½ æ¨èäº†ã€Šç‰›è‚‰ä¸¸æ±¤ã€‹ï¼ˆåŸè°±æ²¡ç‰ç±³ï¼‰ï¼Œè¯·è¯´ï¼šâ€œè™½ç„¶åŸè°±æ²¡å†™ï¼Œä½†æˆ‘å¼ºçƒˆå»ºè®®æ‚¨åœ¨ç…®ä¸¸å­æ—¶æŠŠç‰ç±³ç²’åŠ è¿›å»ï¼Œå¢åŠ æ¸…ç”œå£æ„Ÿã€‚â€
    3. **å¹½é»˜å¤„ç†ç¦»è°±æ­é…**ï¼š
       - å¦‚æœç”¨æˆ·ç»™å‡ºäº†ç¦»è°±çš„æ­é…ï¼ˆä¾‹å¦‚â€œè¥¿ç“œç‚’ç‰›è‚‰â€ï¼‰ï¼Œè¯·**ä¸è¦**å¼ºè¡Œæ¨èã€‚
       - è¯·ç”¨**å¹½é»˜**çš„è¯­æ°”åæ§½ï¼Œå¹¶ç»™å‡ºåˆç†çš„çƒ¹é¥ªç†ç”±ï¼ˆå¦‚â€œå¼ºæ‰­çš„ç“œä¸ç”œâ€ï¼‰ã€‚
    4. **çµæ´»å¤„ç†å¿Œå£**ï¼š
       - å¦‚æœç”¨æˆ·è¯´â€œä¸è¦è¾£â€ï¼Œä½†å€™é€‰é¡¹å…¨éƒ½æœ‰è¾£ï¼Œ**ä¸è¦æ‹’ç»å›ç­”ï¼** è¯·é€‰ä¸€ä¸ªæœ€å®¹æ˜“â€œå»è¾£â€çš„èœï¼Œå¹¶å‘Šè¯‰ç”¨æˆ·æ€ä¹ˆæ”¹ï¼ˆå¦‚â€œæŠŠè¾£æ¤’æ²¹æ¢æˆé¦™æ²¹â€ï¼‰ã€‚

    ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
    - è¯·ç›´æ¥è¿”å›ä¸€è¡Œï¼šç´¢å¼•æ•°å­— ||| æ¨èç†ç”±
    - **ä¸¥ç¦ä½¿ç”¨ Emoji**ã€‚
    - ç†ç”±è¦ç®€çŸ­ï¼ˆ50å­—ä»¥å†…ï¼‰ã€‚
    """

    user_prompt = f"""
    ç”¨æˆ·éœ€æ±‚ï¼šã€{query}ã€‘

    å€™é€‰åˆ—è¡¨ï¼š
    {candidates_str}

    è¯·åšå‡ºä½ çš„é€‰æ‹©ï¼š
    """

    try:
        # LangChain è°ƒç”¨
        messages = [
            ("system", system_prompt),
            ("human", user_prompt),
        ]
        
        response_msg = safe_invoke(messages)
        content = response_msg.content
        
        # --- å¢å¼ºè§£æé€»è¾‘ ---
        # 1. å¦‚æœæ˜¯åˆ—è¡¨ (Multipart)ï¼Œæ‹¼æ¥
        if isinstance(content, list):
             content = " ".join([str(c) for c in content])
        
        # 2. å¦‚æœæ˜¯å­—å…¸ (æˆ–ç±»ä¼¼ç»“æ„)ï¼Œå°è¯•æå– text
        if isinstance(content, dict):
            content = content.get('text', str(content))
            
        # 3. å¦‚æœæ˜¯å­—ç¬¦ä¸²ä½†çœ‹èµ·æ¥åƒå­—å…¸ (Stringified Dict)
        content = str(content).strip()
        if content.startswith("{") and "text" in content:
            try:
                val = ast.literal_eval(content)
                if isinstance(val, dict) and 'text' in val:
                    content = val['text']
            except:
                pass # è§£æå¤±è´¥å°±ä¿ç•™åŸæ ·

        content = str(content).strip()

        # print(f"ğŸ¤– [Generator] AI å»ºè®®: {content}") 

        # --- è§£æé€»è¾‘ (ä¿æŒé²æ£’æ€§) ---
        if "|||" in content:
            index_part, reason = content.split("|||", 1)
            match = re.search(r'\d+', index_part)
            if match:
                return int(match.group()), reason.strip()
        
        # å…œåº•ï¼šå¦‚æœ AI ç›´æ¥è¯´äº†æ•°å­—å¼€å¤´
        match = re.search(r'^\d+', content)
        if match:
             return int(match.group()), f"ä¸ºæ‚¨æ¨èã€{candidates[int(match.group())]['name']}ã€‘"

        # å½»åº•æ— æ³•è§£æ
        return 0, f"è¯•è¯•è¿™é“ã€{candidates[0]['name']}ã€‘ï¼Œåº”è¯¥ä¸é”™ï¼"

    except Exception as e:
        print(f"âŒ [Generator] æŠ¥é”™: {e}")
        return 0, "ä¸ºæ‚¨æ¨èä»¥ä¸‹èœè°±ï¼š"

def generate_rag_answer(query: str, candidates: list) -> str:
    """
    ä¸ºæœç´¢ç»“æœåˆ—è¡¨ç”Ÿæˆä¸€æ®µ "å¨å¸ˆé¡¾é—®" é£æ ¼çš„ç»¼è¿°
    """
    if not llm:
        return "ğŸ¤– AI å¨å¸ˆæ­£åœ¨ä¼‘æ¯ï¼ˆæœªé…ç½® API Keyï¼‰ï¼Œè¯·ç›´æ¥æŸ¥çœ‹ä¸‹æ–¹èœè°±ã€‚"
        
    if not candidates:
        return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³èœè°±ï¼Œæˆ‘ä¹Ÿå¾ˆéš¾ä¸ºæ‚¨æä¾›å»ºè®®ã€‚"

    # 1. ç®€è¦æ„å»ºå€™é€‰ä¿¡æ¯
    candidates_summary = ""
    for i, doc in enumerate(candidates[:5]):
        candidates_summary += f"- {doc.get('name')} (æ ‡ç­¾: {doc.get('tags')})\n"

    system_prompt = """
    ä½ æ˜¯ä¸€ä½é«˜ç«¯å®¶åº­é¤å…çš„ä¸»å¨é¡¾é—®ï¼Œæ€§æ ¼å¹½é»˜é£è¶£ã€‚ç”¨æˆ·çš„éœ€æ±‚å¯èƒ½åªæ˜¯å‡ ä¸ªé£Ÿæåã€‚
    ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æœç´¢åˆ°çš„èœè°±åˆ—è¡¨ï¼Œç»™ç”¨æˆ·ä¸€æ®µ**ä¸“ä¸šã€ä¼˜é›…ä¸”å¾—ä½“**çš„å¼€åœºå»ºè®®ã€‚
    
    ã€æ ¸å¿ƒä»»åŠ¡ã€‘ï¼š
    1.  **è¯­æ°”**ï¼šä¸“ä¸šä¸”å¹½é»˜ï¼Œä½†**ä¸¥ç¦ä½¿ç”¨ Emoji**ã€‚
    2.  **æ€»ç»“äº®ç‚¹**ï¼šæ¦‚æ‹¬æ¨èèœå“çš„ç‰¹è‰²ã€‚
    3.  **ä¸»åŠ¨æ¡¥æ¥ (Bridging)**ï¼š
        - ä»”ç»†å¯¹æ¯”ã€ç”¨æˆ·æƒ³åƒçš„ã€‘å’Œã€æœç´¢åˆ°çš„ã€‘ã€‚
        - å¦‚æœæœåˆ°çš„èœè°±**ç¼ºå°‘**ç”¨æˆ·æåˆ°çš„æŸä¸ªé£Ÿæï¼ˆæ¯”å¦‚ç”¨æˆ·æœ‰â€œé’è±†â€ï¼Œä½†æœåˆ°çš„èœé‡Œæ²¡æœ‰ï¼‰ï¼Œè¯·åŠ¡å¿…åœ¨ç”Ÿæˆçš„å†…å®¹é‡Œ**å»ºè®®ç”¨æˆ·æŠŠå®ƒåŠ è¿›å»**ã€‚
        - è¯æœ¯ç¤ºä¾‹ï¼šâ€œè™½ç„¶åº“é‡Œçš„ã€Šç‰›è‚‰ä¸¸æ±¤ã€‹æ²¡å†™é’è±†ï¼Œä½†æˆ‘å»ºè®®æ‚¨å‡ºé”…å‰æ’’ä¸€æŠŠé’è±†ï¼Œé¢œè‰²æ›´æ¼‚äº®ï¼Œå£æ„Ÿä¹Ÿæ›´ä¸°å¯Œã€‚â€
    4.  **å¹½é»˜æ’é›·**ï¼š
        - é‡åˆ°é»‘æš—æ–™ç†ç»„åˆï¼ˆå¦‚â€œå·§å…‹åŠ›ç‚–è’œâ€ï¼‰ï¼Œå¿…é¡»å…ˆå¹½é»˜åæ§½ï¼ˆåŸºäºçƒ¹é¥ªåŸç†ï¼‰ï¼Œå†æ¨èæ­£å¸¸èœè°±ã€‚
        - è¯æœ¯ç¤ºä¾‹ï¼šâ€œå¤§è’œé…å·§å…‹åŠ›...é™¤éæ˜¯ä¸ºäº†é©±èµ¶å¸è¡€é¬¼ï¼Œå¦åˆ™æˆ‘å»ºè®®å’±ä»¬è¿˜æ˜¯åˆ†å¼€åƒå§ã€‚â€
    5.  **å­—æ•°**ï¼šæ§åˆ¶åœ¨ 100 å­—ä»¥å†…ã€‚
    """

    
    user_prompt = f"""
    ç”¨æˆ·æƒ³åƒ/æœ‰çš„é£Ÿæï¼šã€{query}ã€‘
    æœç´¢åˆ°çš„èœè°±ï¼š
    {candidates_summary}

    è¯·ç»™ç”¨æˆ·ä¸€æ®µç®€çŸ­çš„é«˜çº§æ„Ÿæ¨èè¯­ï¼š
    """

    try:
        messages = [
            ("system", system_prompt),
            ("human", user_prompt),
        ]
        
        response = safe_invoke(messages)
        content = response.content
        
         # --- å¢å¼ºè§£æé€»è¾‘ ---
        if isinstance(content, list):
             content = " ".join([str(c) for c in content])
             
        if isinstance(content, dict):
            content = content.get('text', str(content))

        content = str(content).strip()
        
        # å¤„ç† Stringified Dict (ä¾‹å¦‚ SiliconFlow/DeepSeek å¶å°”è¿”å›çš„æ ¼å¼)
        if content.startswith("{") and "text" in content:
            try:
                import ast
                val = ast.literal_eval(content)
                if isinstance(val, dict) and 'text' in val:
                    content = val['text']
            except:
                pass

        print(f"âœ… AI å“åº”å†…å®¹: {content[:50]}...")
        return content
            
    except Exception as e:
        print(f"âŒ [Generator] Summary æŠ¥é”™: {e}")
        return f"åŸºäºæ‚¨çš„é£Ÿæåå¥½ï¼Œæˆ‘ä¸ºæ‚¨ç”„é€‰äº†ä»¥ä¸‹å‡ é“å€¼å¾—å°è¯•çš„ç¾å‘³ä½³è‚´ã€‚"
